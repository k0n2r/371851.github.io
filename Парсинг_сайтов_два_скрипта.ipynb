{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TwoKeysec/371851.github.io/blob/main/%D0%9F%D0%B0%D1%80%D1%81%D0%B8%D0%BD%D0%B3_%D1%81%D0%B0%D0%B9%D1%82%D0%BE%D0%B2_%D0%B4%D0%B2%D0%B0_%D1%81%D0%BA%D1%80%D0%B8%D0%BF%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  # Импортируем модуль для работы с HTTP-запросами\n",
        "import argparse  # Импортируем модуль для парсинга аргументов командной строки\n",
        "import re  # Импортируем модуль для работы с регулярными выражениями\n",
        "\n",
        "from Demos.security.sspi.socket_server import options  # Импортируем options из указанного модуля\n",
        "\n",
        "# Функция для отправки HTTP-запроса на указанный URL\n",
        "def send_request(url):\n",
        "    try:\n",
        "        # Отправляем GET-запрос на указанный URL с таймаутом в 3 секунды\n",
        "        return requests.get(url, timeout=3)\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        # Если возникает ошибка соединения, то просто продолжаем выполнение программы\n",
        "        pass\n",
        "\n",
        "# Настраиваем парсер аргументов командной строки\n",
        "parser = argparse.ArgumentParser()\n",
        "# Добавляем аргумент -d/--domen для указания домена (по умолчанию 'google.com')\n",
        "parser.add_argument('-d', '--domen', default='google.com', dest='domenPars')\n",
        "# Добавляем аргумент -n/--name для указания имени файла (по умолчанию 'res.txt')\n",
        "parser.add_argument('-n', '--name', default='res.txt', dest='file_name')\n",
        "# Разбираем аргументы командной строки\n",
        "options = parser.parse_args()\n",
        "\n",
        "# Получаем домен, который был передан в аргументах\n",
        "url = options.domenPars\n",
        "\n",
        "# Отправляем запрос к указанному домену\n",
        "resp = send_request(url)\n",
        "\n",
        "# Шаблон для поиска всех значений атрибута href в HTML\n",
        "url_site = '(?:href=\")(.*?)\"'\n",
        "# Ищем все совпадения в полученном HTML-коде\n",
        "href_find = re.findall(url_site, resp.text)\n",
        "\n",
        "# Выводим найденные ссылки\n",
        "print(href_find)\n",
        "\n",
        "# Примечания:\n",
        "# Далее, скрипт импортируется в Kali Linux:\n",
        "# 1. Переходим в директорию с данным скриптом.\n",
        "# 2. Запускаем команду:\n",
        "#    python3 (название скрипта) -d (полное наименование сайта для парсинга)\n",
        "#    Пример: python3 crawler.py -d https://www.kali.org/\n"
      ],
      "metadata": {
        "id": "7co6-I3-b_n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  # Импортируем модуль для работы с HTTP-запросами\n",
        "import argparse  # Импортируем модуль для парсинга аргументов командной строки\n",
        "import re  # Импортируем модуль для работы с регулярными выражениями\n",
        "\n",
        "from Demos.security.sspi.socket_server import options  # Импортируем options из указанного модуля\n",
        "\n",
        "# Функция для отправки HTTP-запроса и поиска ссылок на странице\n",
        "def find_request(url):\n",
        "    try:\n",
        "        # Отправляем GET-запрос на указанный URL с таймаутом 3 секунды\n",
        "        resp = requests.get(url, timeout=3)\n",
        "        # Возвращаем список найденных ссылок, которые соответствуют шаблону url_site\n",
        "        return re.findall(url_site, resp.text)\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        # Игнорируем ошибку соединения, если сайт недоступен\n",
        "        pass\n",
        "\n",
        "# Функция для обработки аргументов командной строки\n",
        "def parser():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # Добавляем аргумент -d/--domen для указания домена (по умолчанию 'google.com')\n",
        "    parser.add_argument('-d', '--domen', default='google.com', dest='domenPars')\n",
        "    # Добавляем аргумент -n/--name для указания имени файла (по умолчанию 'res.txt')\n",
        "    parser.add_argument('-n', '--name', default='res.txt', dest='file_name')\n",
        "    # Возвращаем разобранные аргументы\n",
        "    options = parser.parse_args()\n",
        "    return options\n",
        "\n",
        "# Получаем домен из аргументов командной строки\n",
        "url = options.domenPars\n",
        "# Шаблон для поиска всех значений атрибута href в HTML\n",
        "url_site = '(?:href=\")(.*?)\"'\n",
        "# Вызываем функцию find_request для поиска всех ссылок на указанной странице\n",
        "href_find = find_links(url)\n",
        "\n",
        "# Выводим найденные ссылки\n",
        "for link in href_find:\n",
        "    print(link)\n",
        "\n",
        "# Примечания:\n",
        "# Далее, скрипт импортируется в Kali Linux:\n",
        "# 1. Переходим в директорию с данным скриптом.\n",
        "# 2. Запускаем команду:\n",
        "#    python3 (название скрипта) -d (полное наименование сайта для парсинга)\n",
        "#    Пример: python3 crawler.py -d https://www.kali.org/\n"
      ],
      "metadata": {
        "id": "mJeainyMdzQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Парсинг сайтов - два скрипта",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}